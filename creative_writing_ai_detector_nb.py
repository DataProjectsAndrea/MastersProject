# -*- coding: utf-8 -*-
"""Creative_Writing_AI_Detector_NB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hzZLtZyEZLvOpP1i99iH6CLNTnu5U5N-

**Disclaimer:** There is no guarantee this detection tool provides reliable results and the creator takes no responsibility for the results or for troubleshooting any issues you may encounter.

Permission is given for reusers to distribute, remix, adapt, and build upon the material in any medium or format for noncommercial purposes only, and only so long as attribution is given to the creator. Adapted from https://creativecommons.org/share-your-work/cclicenses/.

Firstly, save a copy of this script in your drive to allow you to edit as required. This is also to ensure there are no instances of many people running the same script at the same time which could create issues.

Below are details on the files that must be uploaded into the folder on the left hand side of this screen.

The "Training Set" must have two columns:


*   First column must have the header "texts" and each row contains an example
*   Second column must have the header "label" and each row either has a "1" beside AI text or a "0" beside human text

The "Test Set" can contain one or two column:


*   The first column is mandatory and must have the header "texts" and each row contains an example for AI detection.
*   The second column is optional and can be used if you want to test a set of know human and AI text to determine the accuracy, precision, recall and F1 score of your data set. This must have the header "label" if included and a "1" for AI text and a "0" for human text.

Output from Script:


*   If only text examples are included for the test set, the output is a csv download which contains your test text examples with the prediciton included in a new column. Additionally the training accuracy, precision, recall and F1 score is shown.

*   If labels are also provided for the test set then, in addition to the above, a confusion metric will be shown and metrics for the test set.

This detector can be used in multiple ways:


1.   **Evaluate a set of text examples for AI Detection using provided training set** - trained with the prepared data set of creative writing from Agatha Christie Novels.
  Simply upload the training set csv available from the Git Respoitory and upload your test set csv, copy the paths into the correct variables below, then press Runtime > Run all from the menu above.

2.   **Evaluate the training data's ability against a test set of known examples** - trained with the prepared data set of creative writing from Agatha Christie Novels.
  Simply upload the training set csv available from the Git Respoitory and upload your test set csv which contains the label column, copy the paths into the correct variables below, then hit Runtime > Run all from the menu bar above.

3. **Evaluate NEW training data's ability against a test set of known examples**
  Simply upload your new training set csv and upload your test set csv which have both been set up as described above, copy the paths into the correct variables below, then hit Runtime > Run all from the menu bar above.

4. **Evaluate a set of text examples for AI Detection using NEW training set**
  Simply upload your new training set csv and upload your test set csv which will only have the first column filled, copy the paths into the correct variables below, then hit Runtime > Run all from the menu bar above.
"""

# Upload your training and test set using the folder icon on the left side of the screen
# Copy each path and paste it between the corresponding quotes marks below
# then press Runtime > Run


training_set_path = "/content/New_training_6_novels.csv"

test_set_path = "/content/1920s_crime_author_noLabels.csv"

#@title Code is contained here.

# import libraries
import pandas as pd
import numpy as np
from sklearn import model_selection, naive_bayes
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score


np.random.seed(500)
Corpus = pd.read_csv(training_set_path, encoding='latin-1')
separate_test = pd.read_csv(test_set_path, encoding='latin-1')

# confirm no blank rows
Corpus['texts'].dropna(inplace=True)

# split out training and test data
Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['texts'],Corpus['label'],test_size=0.3, random_state=16)

# set alpha
alpha = 0.7

# create the vocabulary
vectorizer = CountVectorizer()
vectorizer.fit(Corpus['texts'])
Train_X_countv = vectorizer.transform(Train_X)
Test_X_countv = vectorizer.transform(Test_X)

# prep test set
Val_X_countv = vectorizer.transform(separate_test['texts'])

if 'label' in separate_test.columns:
  val_y = separate_test['label']

# fit the training dataset on the NB classifier MultinomialN
Naive = naive_bayes.MultinomialNB(alpha=alpha)
Naive.fit(Train_X_countv,Train_Y)

# predict the labels on test dataset
predictions_NB_M = Naive.predict(Test_X_countv)

# predict values on separate test set
predictions_NB_M_val = Naive.predict(Val_X_countv)

from datetime import datetime

today = datetime.now()

from sklearn.metrics import confusion_matrix
# Comparing the predictions against the actual observations in y_val

if 'label' in separate_test.columns:
  print("Confusion Matrix for your test:", test_set_path, today)

  cm = confusion_matrix(val_y, predictions_NB_M_val, labels=Naive.classes_)
  disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                                 display_labels=Naive.classes_)
  disp.plot()

  plt.show()

# Use accuracy_score function to get the accuracy
print("Naive Bayes Training Accuracy Score -> ",accuracy_score(Test_Y, predictions_NB_M))
print("Naive Bayes Training Precision Score -> ",precision_score(Test_Y, predictions_NB_M))
print("Naive Bayes Training Recall Score -> ",recall_score(Test_Y, predictions_NB_M))
print("Naive Bayes Training F1 Score -> ",f1_score(Test_Y, predictions_NB_M))

if 'label' in separate_test.columns:
    print("Naive Bayes Test Accuracy Val Score -> ",accuracy_score(val_y, predictions_NB_M_val))
    print("Naive Bayes Test precision Val Score -> ",precision_score(val_y, predictions_NB_M_val))
    print("Naive Bayes Test recall Val Score -> ",recall_score(val_y, predictions_NB_M_val))
    print("Naive Bayes Test F1 Val Score -> ",f1_score(val_y, predictions_NB_M_val))

separate_test['predictions'] = predictions_NB_M_val

separate_test['AI or Human?'] = np.where(separate_test['predictions']== 1, "This text has most likely been generated by AI", "This text has mostly likely been written by a human")
separate_test.head()

separate_test.to_csv("Classifier_Results.csv", index=False, encoding='utf-8')

print("Please see folder on left handside for your csv for test run:", test_set_path, today)