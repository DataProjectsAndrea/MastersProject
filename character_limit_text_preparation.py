# -*- coding: utf-8 -*-
"""Character_limit_Text_Preparation_murder_on_links.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_XgGgmmrqs3L-PkyuOi0vRAzPyenLQhs
"""

# import libraries

import pandas as pd
import csv
import re

# load text
filename = '/content/The_secret_Chimn.txt'
file = open(filename, 'rt')
text = file.read()
file.close()

print(text)

replaced_text = re.sub('END OF THE PROJECT GUTENBERG EBOOK((.|\n)*)', '', text)
start_removed = re.sub('(?s).*START OF THE PROJECT GUTENBERG', '', replaced_text)

print(replaced_text)

print(start_removed)

# load text reduced
filename_reduced = '/content/big_four.txt'
file = open(filename_reduced, 'rt')
text = file.read()
file.close()

replaced_text = re.sub('\n', ' ', text)
replaced_text = re.sub('  ', ' ', replaced_text)

print(replaced_text)

# split string into list based on full stop
list_words = replaced_text.split(".")

print(list_words)

# add the full stop back
new_words = []
for item in list_words:
  term = item + "."
  new_words.append(term)

print(new_words)

# add sentences together based on character length
# based on average 5 characters per word plus one space character
# 100 words = 600  91% to 125% = 550, 750
# 500 words = 3000   2730, 3750
# 1000 words = 6000  5460, 7500
# 5000 words = 30000   27300, 37500
# 15,000 therefore range 13650, 18750
#100, 500, 1000 and 5000

# open up range more 400 - 800 then 2500 - 3500
list_of_ids = new_words

list_of_query_strings = []
one_string = list_of_ids[0]

# generate random integer values
from random import seed
from random import randint
# seed random number generator
seed(1)
# # generate some integers
# value = randint(400, 800)
# print(value)

# Iterate over each id
for id_ in list_of_ids[1:]:
    value = randint(550, 750)
    print(value)
    number = value
    # Add the id to the substring if it doesn't make it to large
    if len(one_string) + len(id_) < number:
        one_string += id_
    # Substring too large, so add to the list and reset
    else:
        list_of_query_strings.append(one_string)
        one_string = id_

list_of_query_strings

# remove double quotes or spaces at start
updated_list = []
for item in list_of_query_strings:
 replaced_text = re.sub('^" "|^""|^” “', '"', item)
 replaced_text2 = re.sub('^\s|^_|^\\,|^\\?|^\\!|^', '', replaced_text)
 replaced_text3 = re.sub('"$ "|$""', '"', replaced_text2)
 replaced_text4 = re.sub('$\s|$_|$\\,|$\\?|$\\!|$', '', replaced_text3)
 updated_list.append(replaced_text4)

print(updated_list)

# create csv of results

# Create the pandas DataFrame
df = pd.DataFrame(updated_list)

# df['fullstop'] = "."
df["final"] = df[0]
df2 = df[['final']].copy()

print(df2)

df2.to_csv("approx_100_words_2_more.csv", index=False, encoding='utf-8')

all_3 = pd.read_csv('/content/approx_1000_words_all.csv')
all_2 = pd.read_csv('/content/approx_100_words_all.csv')
all_1 = pd.read_csv('/content/approx_3000_words_all.csv')
all_4 = pd.read_csv('/content/approx_500_words_all.csv')
#all_5 = pd.read_csv('/content/results_test_df5_with_3000_max.csv')

all_3_list = all_3['final'].tolist()
all_2_list = all_2['final'].tolist()
all_1_list = all_1['final'].tolist()
all_4_list = all_4['final'].tolist()
#all_5_list = all_5['0'].tolist()

all_3_list

all_lists = all_3_list + all_2_list + all_1_list + all_4_list + all_1_list + all_1_list + all_1_list + all_1_list + all_1_list + all_3_list + all_3_list + all_3_list + all_3_list + all_3_list + all_3_list
all_lists

import random


#random_list = random.shuffle(all_lists)

df = pd.DataFrame(all_lists)

final_df = pd.read_csv('/content/approx_100_words_2_more.csv')

df

df_2 = df.sample(frac = 1)

df_2

df_2.to_csv("100_words_2_more_random_big4.csv", index=False, encoding='utf-8')

final_df = pd.read_csv('/content/100_500_only.csv')

final = df_2[0].tolist()

# remove double quotes or spaces at start
updated_list = []
for item in final:
 replaced_text = re.sub('^” “', '“', item)
 updated_list.append(replaced_text)

print(updated_list)

df_2 = pd.DataFrame(updated_list)

df_2.to_csv("final_prepared_input_data_2.csv", index=False, encoding='utf-8')

# Import necessary libraries
import numpy as np
from scipy import stats

# Given student scores
student_scores = np.array([1,2,2,3,3,4,4,4,4,4,4,4,5,5,6,7,7,7,8])


# Hypothesized population mean
mu = 5

# Perform one-sample t-test
t_stat, p_value = stats.ttest_1samp(student_scores, mu)
print("T statistic:", t_stat)
print("P-value:", p_value)

# Setting significance level
alpha = 0.05

# Interpret the results
if p_value < alpha:
    print("Reject the null hypothesis; there is a significant difference between the sample mean and the hypothesized population mean.")
else:
    print("Fail to reject the null hypothesis; there is no significant difference between the sample mean and the hypothesized population mean.")