# -*- coding: utf-8 -*-
"""NB_models_countvector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yTJ82FZDvulseayC5_c_Yw3CDGnTaVE1
"""

import pandas as pd
import numpy as np
from sklearn import model_selection, naive_bayes, svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

np.random.seed(500)
Corpus = pd.read_csv(r"/content/New_training_6_novels.csv",encoding='latin-1')
sep_test = pd.read_csv(r"/content/1920s_crime_author.csv", encoding='latin-1')

# confirm no blank rows
Corpus['texts'].dropna(inplace=True)

Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['texts'],Corpus['label'],test_size=0.3, random_state=16)

alpha = 0.7

# create the vocabulary
vectorizer = CountVectorizer()
vectorizer.fit(Corpus['texts'])
Train_X_countv = vectorizer.transform(Train_X)
Test_X_countv = vectorizer.transform(Test_X)

# prep test set

Val_X_countv = vectorizer.transform(sep_test['texts'])
val_y = sep_test['label']

# fit the training dataset on the NB classifier MultinomialN
Naive = naive_bayes.MultinomialNB(alpha=alpha)
Naive.fit(Train_X_countv,Train_Y)
# predict the labels on validation dataset
predictions_NB_M = Naive.predict(Test_X_countv)

#val set
predictions_NB_M_val = Naive.predict(Val_X_countv)

from sklearn.metrics import confusion_matrix
#Comparing the predictions against the actual observations in y_val
# double check set up cm = confusion_matrix(y_pred, y_test)

cm = confusion_matrix(val_y, predictions_NB_M_val, labels=Naive.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                               display_labels=Naive.classes_)
disp.plot()

plt.show()
# Use accuracy_score function to get the accuracy
print("Naive Bayes Accuracy Score : ",accuracy_score(Test_Y, predictions_NB_M))
print("Naive Bayes Precision Score : ",precision_score(Test_Y, predictions_NB_M))
print("Naive Bayes Recall Score : ",recall_score(Test_Y, predictions_NB_M))
print("Naive Bayes F1 Score : ",f1_score(Test_Y, predictions_NB_M))
print("Naive Bayes Accuracy Val Score : ",accuracy_score(val_y, predictions_NB_M_val))
print("Naive Bayes precision Val Score : ",precision_score(val_y, predictions_NB_M_val))
print("Naive Bayes recall Val Score : ",recall_score(val_y, predictions_NB_M_val))
print("Naive Bayes F1 Val Score : ",f1_score(val_y, predictions_NB_M_val))

from sklearn.naive_bayes import GaussianNB
clf = GaussianNB()
clf.fit(Train_X_countv.toarray(),Train_Y)

predictions_NB_G = clf.predict(Test_X_countv.toarray())

#val set
predictions_NB_G_val = clf.predict(Val_X_countv.toarray())
# Use accuracy_score function to get the accuracy
# print("Naive Bayes G Accuracy Score : ",accuracy_score(Test_Y, predictions_NB_G))
# print("Naive Bayes G F1 Score : ",f1_score(Test_Y, predictions_NB_G))
# print("Naive Bayes G Accuracy Val Score : ",accuracy_score(val_y, predictions_NB_G_val))
# # print("Naive Bayes G precision Val Score : ",precision_score(val_y, predictions_NB_G_val))
# # print("Naive Bayes G recall Val Score : ",recall_score(val_y, predictions_NB_G_val))
# print("Naive Bayes G F1 Val Score : ",f1_score(val_y, predictions_NB_G_val))

sep_test['predictions'] = predictions_NB_M_val

print(sep_test)

sep_test.to_csv("NB_approx_100_words_validation_set_results_correct.csv", index=False, encoding='utf-8')

from sklearn.naive_bayes import ComplementNB
clf_c = ComplementNB(alpha=alpha)
clf_c.fit(Train_X_countv.toarray(),Train_Y)

predictions_NB_C = clf_c.predict(Test_X_countv.toarray())

#val set
predictions_NB_C_val = clf_c.predict(Val_X_countv.toarray())
# # Use accuracy_score function to get the accuracy
# print("Naive Bayes C Accuracy Score : ",accuracy_score(Test_Y, predictions_NB_C))
# print("Naive Bayes C F1 Score : ",f1_score(Test_Y, predictions_NB_C))
# print("Naive Bayes C Accuracy Val Score : ",accuracy_score(val_y, predictions_NB_C_val))
# # print("Naive Bayes C precision Val Score : ",precision_score(val_y, predictions_NB_C_val))
# # print("Naive Bayes C recall Val Score : ",recall_score(val_y, predictions_NB_C_val))
# print("Naive Bayes C F1 Val Score : ",f1_score(val_y, predictions_NB_C_val))


from sklearn.naive_bayes import BernoulliNB
clf_b = BernoulliNB(alpha=alpha)
clf_b.fit(Train_X_countv.toarray(),Train_Y)

predictions_NB_B = clf_b.predict(Test_X_countv.toarray())

#val set
predictions_NB_B_val = clf_b.predict(Val_X_countv.toarray())
# Use accuracy_score function to get the accuracy
# print("Naive Bayes B Accuracy Score : ",accuracy_score(Test_Y, predictions_NB_B))
# print("Naive Bayes B F1 Score : ",f1_score(Test_Y, predictions_NB_B))
# print("Naive Bayes B Accuracy Val Score : ",accuracy_score(val_y, predictions_NB_B_val))
# # print("Naive Bayes B precision Val Score : ",precision_score(val_y, predictions_NB_B_val))
# # print("Naive Bayes B recall Val Score : ",recall_score(val_y, predictions_NB_B_val))
# print("Naive Bayes B F1 Val Score : ",f1_score(val_y, predictions_NB_B_val))